{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71fb8cdb",
   "metadata": {},
   "source": [
    "\n",
    "### **Cell 1: Imports and Setup**\n",
    "\n",
    "This cell imports the necessary libraries for data manipulation, machine learning, and plotting. It also suppresses warnings for cleaner output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1162d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cbab53",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Cell 2: Configuration of Algorithm Results**\n",
    "\n",
    "This cell defines a dictionary that maps algorithm names to their corresponding result files. This centralized configuration makes it easy to manage file paths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping algorithm names to their result file paths\n",
    "algorithm_results = {\n",
    "    # CATEGORICAL ALGORITHMS\n",
    "    'AVF': r'..\\..\\..\\results\\decision_tree\\algorithms\\AVF\\AVF.csv',\n",
    "    'CBRW': r'..\\..\\..\\results\\decision_tree\\algorithms\\CBRW\\CBRW.csv',\n",
    "    'CompreX': r'..\\..\\..\\results\\decision_tree\\algorithms\\CompreX\\COMPREX.csv',\n",
    "    'FPOF': r'..\\..\\..\\results\\decision_tree\\algorithms\\FPOF\\FPOF.csv',\n",
    "    'POP': r'..\\..\\..\\results\\decision_tree\\algorithms\\POP\\POP.csv',\n",
    "    'SCAN': r'..\\..\\..\\results\\decision_tree\\algorithms\\SCAN\\SCAN.csv',\n",
    "    'SDRW': r'..\\..\\..\\results\\decision_tree\\algorithms\\SDRW\\SDRW.csv',\n",
    "    'Zero++': r'..\\..\\..\\results\\decision_tree\\algorithms\\Zero++\\ZERO++.csv',\n",
    "    \n",
    "    # NUMERICAL ALGORITHMS WITH ENCODINGS\n",
    "    'LOF_ca': r'..\\..\\..\\results\\decision_tree\\algorithms\\LOF\\ca\\CA.csv',\n",
    "    'KNN_ca': r'..\\..\\..\\results\\decision_tree\\algorithms\\KNN\\ca\\CA.csv',\n",
    "    'iForest_ca': r'..\\..\\..\\results\\decision_tree\\algorithms\\iForest\\ca\\CA.csv',\n",
    "    'FastABOD_ca': r'..\\..\\..\\results\\decision_tree\\algorithms\\FastABOD\\ca\\CA.csv',\n",
    "    'DeepSVDD_ca': r'..\\..\\..\\results\\decision_tree\\algorithms\\DeepSVDD\\ca\\CA.csv',\n",
    "    'McCatch_ca': r'..\\..\\..\\results\\decision_tree\\algorithms\\McCatch\\ca\\CA.csv',\n",
    "    \n",
    "    'LOF_idf': r'..\\..\\..\\results\\decision_tree\\algorithms\\LOF\\idf\\IDF.csv',\n",
    "    'KNN_idf': r'..\\..\\..\\results\\decision_tree\\algorithms\\KNN\\idf\\IDF.csv',\n",
    "    'iForest_idf': r'..\\..\\..\\results\\decision_tree\\algorithms\\iForest\\idf\\IDF.csv',\n",
    "    'FastABOD_idf': r'..\\..\\..\\results\\decision_tree\\algorithms\\FastABOD\\idf\\IDF.csv',\n",
    "    'DeepSVDD_idf': r'..\\..\\..\\results\\decision_tree\\algorithms\\DeepSVDD\\idf\\IDF.csv',\n",
    "    'McCatch_idf': r'..\\..\\..\\results\\decision_tree\\algorithms\\McCatch\\idf\\IDF.csv',\n",
    "    \n",
    "    'LOF_onehot': r'..\\..\\..\\results\\decision_tree\\algorithms\\LOF\\one_hot\\ONE_HOT.csv',\n",
    "    'KNN_onehot': r'..\\..\\..\\results\\decision_tree\\algorithms\\KNN\\one_hot\\ONE_HOT.csv',\n",
    "    'iForest_onehot': r'..\\..\\..\\results\\decision_tree\\algorithms\\iForest\\one_hot\\ONE_HOT.csv',\n",
    "    'FastABOD_onehot': r'..\\..\\..\\results\\decision_tree\\algorithms\\FastABOD\\one_hot\\ONE_HOT.csv',\n",
    "    'DeepSVDD_onehot': r'..\\..\\..\\results\\decision_tree\\algorithms\\DeepSVDD\\one_hot\\ONE_HOT.csv',\n",
    "    'McCatch_onehot': r'..\\..\\..\\results\\decision_tree\\algorithms\\McCatch\\one_hot\\ONE_HOT.csv',\n",
    "    \n",
    "    'LOF_pivot': r'..\\..\\..\\results\\decision_tree\\algorithms\\LOF\\pivot\\PIVOT.csv',\n",
    "    'KNN_pivot': r'..\\..\\..\\results\\decision_tree\\algorithms\\KNN\\pivot\\PIVOT.csv',\n",
    "    'iForest_pivot': r'..\\..\\..\\results\\decision_tree\\algorithms\\iForest\\pivot\\PIVOT.csv',\n",
    "    'FastABOD_pivot': r'..\\..\\..\\results\\decision_tree\\algorithms\\FastABOD\\pivot\\PIVOT.csv',\n",
    "    'DeepSVDD_pivot': r'..\\..\\..\\results\\decision_tree\\algorithms\\DeepSVDD\\pivot\\PIVOT.csv',\n",
    "    'McCatch_pivot': r'..\\..\\..\\results\\decision_tree\\algorithms\\McCatch\\pivot\\PIVOT.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ba145",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Cell 3: Load and Prepare Dataset Summary**\n",
    "\n",
    "This cell loads a summary of all datasets, sorts them, and manually annotates the 'best' performing algorithm for each one. This annotated DataFrame will be used as the basis for training the decision tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset summary file\n",
    "df_summary = pd.read_csv(r'..\\..\\resume_datasets.csv', sep=';')\n",
    "df_summary = df_summary.sort_values(by='file').reset_index(drop=True)\n",
    "\n",
    "# Manually annotate the best performing algorithm for each dataset\n",
    "# This list serves as the ground truth (target variable) for the decision tree.\n",
    "best_algorithms = [\n",
    "    'SDRW', 'SDRW', 'SCAN', 'iForest_pivot', 'SCAN', 'SDRW', 'iForest_pivot',\n",
    "    'POP', 'KNN_one', 'iForest_idf', 'SCAN', 'AVF', 'SDRW',\n",
    "    'AVF', 'CompreX', 'CBRW', 'CompreX', 'iForest_one', 'FastABOD_one', 'SCAN', 'SCAN',\n",
    "    'POP', 'SCAN', 'iForest_idf', 'POP', 'KNN_ca', 'KNN_one', 'KNN_one',\n",
    "    'iForest_one', 'iForest_one', 'iForest_one', 'iForest_one',\n",
    "    'iForest_one', 'CBRW', 'CBRW', 'CBRW', 'CBRW', 'CBRW', 'CBRW', 'CBRW',\n",
    "    'CBRW', 'CBRW', 'CBRW', 'KNN_one', 'SCAN', 'AVF', 'POP'\n",
    "]\n",
    "df_summary['best'] = best_algorithms\n",
    "\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d31d3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Cell 4: Create and Save the Decision Tree Input File**\n",
    "\n",
    "Here, we select the relevant features from the summary DataFrame, add placeholder columns for 'context' and 'class', and save the result to a CSV file that will be used to train the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25258ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for the decision tree model\n",
    "df_for_tree = df_summary.drop(columns=['outliers', '%_outliers', 'type', 'attr_numerics', 'attr_categorics', 'attr_binaries'])\n",
    "\n",
    "# Add placeholder columns (to be filled manually or by another process)\n",
    "df_for_tree['context'] = ''\n",
    "df_for_tree['class'] = '' # This will be the target variable\n",
    "\n",
    "# Save the prepared data to a CSV file\n",
    "output_path = r'decision_tree.csv'\n",
    "df_for_tree.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Data for decision tree saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd82c0cf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Cell 5: Train, Evaluate, and Visualize the Decision Tree**\n",
    "\n",
    "This is the main block for the machine learning task. It loads one of the prepared datasets, splits it into training and testing sets, trains a `DecisionTreeClassifier`, evaluates its performance, and visualizes the resulting tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2630245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop is set up to process multiple tree configurations,\n",
    "# but the 'break' statement causes it to run only for the first item.\n",
    "# This is useful for testing one configuration at a time.\n",
    "\n",
    "tree_configurations = [\n",
    "    {'name': 'Binary Tree', 'file': 'decision_tree_binary.csv'},\n",
    "    #{'name': 'Binary Tree (Majority)', 'file': 'decision_tree_majority.csv'},\n",
    "    #{'name': 'Algorithm Tree', 'file': 'decision_tree_algorithm.csv'},\n",
    "]\n",
    "\n",
    "for config in tree_configurations:\n",
    "    tree_name = config['name']\n",
    "    file_name = config['file']\n",
    "    file_path = f'{file_name}'\n",
    "    \n",
    "    print(f\"--- Processing: {tree_name} ---\")\n",
    "\n",
    "    # 1. Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop(columns=['file', 'source'])\n",
    "\n",
    "    # 2. Separate features (X) and target (y)\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    # 3. Split data into training and testing sets (70% train, 30% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # 4. Create and train the Decision Tree model\n",
    "    model = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 5. Evaluate the model on the test and train set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    print(f\"Training Accuracy: {accuracy_train:.2f}\")\n",
    "    print(f\"Test Accuracy: {accuracy_test:.2f}\")\n",
    "\n",
    "    # 6. Perform 10-fold cross-validation for a more robust evaluation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=10)\n",
    "    print(f\"Cross-validation accuracies: {cv_scores}\")\n",
    "    print(f\"Average CV Accuracy: {cv_scores.mean():.2f}\")\n",
    "\n",
    "    # 7. Visualize and save the decision tree\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plot_tree(model, feature_names=X.columns, class_names=sorted(list(set(y))), filled=True, rounded=True)\n",
    "    plt.title(tree_name, fontsize=20)\n",
    "    \n",
    "    # Save the figure\n",
    "    output_image_path = f\"{file_name.replace('.csv', '')}.png\"\n",
    "    plt.savefig(output_image_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # The break statement ensures only the first configuration is run.\n",
    "    # Remove it to run for all configurations in the list.\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc90ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Cell 6: Validation on New Data**\n",
    "\n",
    "This final section demonstrates how to use the trained model to make predictions on a new, unseen validation dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the new validation data\n",
    "df_validation = pd.read_csv(f'decision_tree_validation.csv')\n",
    "X_validation = df_validation.iloc[:, 1:] # Assuming the first column is an identifier\n",
    "\n",
    "print(\"Validation Features (X):\")\n",
    "print(X_validation)\n",
    "\n",
    "# 2. Use the trained model from the previous cell to make predictions\n",
    "validation_predictions = model.predict(X_validation)\n",
    "print(f\"\\nModel Predictions: {validation_predictions}\")\n",
    "\n",
    "# 3. Define the ground truth labels for the validation set\n",
    "y_validation_true = ['numeric', 'numeric', 'categorical', 'categorical', 'numeric', \n",
    "                     'numeric', 'categorical', 'numeric', 'numeric', 'numeric']\n",
    "print(f\"True Labels:       {y_validation_true}\")\n",
    "\n",
    "# 4. (Optional) Calculate accuracy on the validation set\n",
    "validation_accuracy = accuracy_score(y_validation_true, validation_predictions)\n",
    "print(f\"\\nValidation Accuracy: {validation_accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
